{
  "paper_id": "Understanding_Write_Behaviors_of_Storage_Backends_in_Ceph_Object_Store",
  "entities": [
    {
      "id": "E1",
      "label": "SSD",
      "type": "Instance",
      "taxonomy_path": "SSD",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD"
    },
    {
      "id": "E2",
      "label": "EnvironmentalAndOperationalContext",
      "type": "Instance",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD/EnvironmentalAndOperationalContext"
    },
    {
      "id": "E3",
      "label": "WorkloadProfile",
      "type": "Instance",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext/WorkloadProfile",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD/EnvironmentalAndOperationalContext/WorkloadProfile"
    },
    {
      "id": "E4",
      "label": "Random",
      "type": "Class",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext/WorkloadProfile/AccessPattern",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD/EnvironmentalAndOperationalContext/WorkloadProfile/AccessPattern"
    },
    {
      "id": "E5",
      "label": "Write-Heavy",
      "type": "Class",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext/WorkloadProfile/ReadWriteMix",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD/EnvironmentalAndOperationalContext/WorkloadProfile/ReadWriteMix"
    },
    {
      "id": "E6",
      "label": "4KB",
      "type": "Class",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext/WorkloadProfile/BlockSize",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD/EnvironmentalAndOperationalContext/WorkloadProfile/BlockSize"
    },
    {
      "id": "E7",
      "label": "QD128",
      "type": "Instance",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext/WorkloadProfile/QueueDepth",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD/EnvironmentalAndOperationalContext/WorkloadProfile/QueueDepth"
    },
    {
      "id": "E8",
      "label": "IOPS",
      "type": "Class",
      "taxonomy_path": "SSD/MetricsHealthAndState/Performance/IOPS",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD/MetricsHealthAndState/Performance/IOPS"
    },
    {
      "id": "E9",
      "label": "Average Latency",
      "type": "Class",
      "taxonomy_path": "SSD/MetricsHealthAndState/Performance/Average Latency",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD/MetricsHealthAndState/Performance/Average%20Latency"
    },
    {
      "id": "E10",
      "label": "99th Percentile Latency",
      "type": "Class",
      "taxonomy_path": "SSD/MetricsHealthAndState/Performance/99th Percentile Latency",
      "taxonomy_uri": "http://example.org/ssd/taxonomy/SSD/MetricsHealthAndState/Performance/99th%20Percentile%20Latency"
    }
  ],
  "triples": [
    {
      "s": "E1",
      "p": "operatesUnder",
      "o": "E2",
      "evidence": "We have used a microbenchmark and a long-term workload of 4KB random writes to measure write traffic of various Ceph storage backends on both HDDs and SSDs.",
      "confidence": 0.9
    },
    {
      "s": "E2",
      "p": "hasWorkloadProfile",
      "o": "E3",
      "evidence": "We have used a microbenchmark and a long-term workload of 4KB random writes to measure write traffic of various Ceph storage backends on both HDDs and SSDs.",
      "confidence": 0.9
    },
    {
      "s": "E3",
      "p": "hasAccessPattern",
      "o": "E4",
      "evidence": "We have used a microbenchmark and a long-term workload of 4KB random writes to measure write traffic of various Ceph storage backends on both HDDs and SSDs.",
      "confidence": 0.9
    },
    {
      "s": "E3",
      "p": "hasReadWriteMix",
      "o": "E5",
      "evidence": "We have used a microbenchmark and a long-term workload of 4KB random writes to measure write traffic of various Ceph storage backends on both HDDs and SSDs.",
      "confidence": 0.9
    },
    {
      "s": "E3",
      "p": "hasBlockSize",
      "o": "E6",
      "evidence": "We have used a microbenchmark and a long-term workload of 4KB random writes to measure write traffic of various Ceph storage backends on both HDDs and SSDs.",
      "confidence": 0.9
    },
    {
      "s": "E3",
      "p": "hasQueueDepth",
      "o": "E7",
      "evidence": "Perform 4KiB random writes with the queue depth of 128 (QD=128) using fio to the krbd partition until the total write amount reaches 90% of the capacity.",
      "confidence": 0.9
    },
    {
      "s": "E1",
      "p": "improves",
      "o": "E8",
      "evidence": "BlueStore shows the stable performance on both HDDs and SSDs in terms of IOPS, WAF and latency.",
      "confidence": 0.8
    },
    {
      "s": "E1",
      "p": "improves",
      "o": "E9",
      "evidence": "BlueStore shows the stable performance on both HDDs and SSDs in terms of IOPS, WAF and latency.",
      "confidence": 0.8
    },
    {
      "s": "E1",
      "p": "improves",
      "o": "E10",
      "evidence": "BlueStore shows the stable performance on both HDDs and SSDs in terms of IOPS, WAF and latency.",
      "confidence": 0.8
    }
  ],
  "axioms": [
    "operatesUnder rdfs:domain SSD; rdfs:range EnvironmentalAndOperationalContext.",
    "hasWorkloadProfile rdfs:domain EnvironmentalAndOperationalContext; rdfs:range WorkloadProfile.",
    "hasAccessPattern rdfs:domain WorkloadProfile; rdfs:range AccessPattern.",
    "hasReadWriteMix rdfs:domain WorkloadProfile; rdfs:range ReadWriteMix.",
    "hasBlockSize rdfs:domain WorkloadProfile; rdfs:range BlockSize.",
    "hasQueueDepth rdfs:domain WorkloadProfile; rdfs:range QueueDepth.",
    "improves rdfs:domain SSD; rdfs:range Performance."
  ],
  "mappings": [
    {
      "label": "Random",
      "entity_id": "E4",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext/WorkloadProfile/AccessPattern",
      "mapping_decision": "exact",
      "notes": "Random access pattern is explicitly mentioned in the workload description."
    },
    {
      "label": "Write-Heavy",
      "entity_id": "E5",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext/WorkloadProfile/ReadWriteMix",
      "mapping_decision": "exact",
      "notes": "The workload is focused on write amplification, indicating a write-heavy mix."
    },
    {
      "label": "4KB",
      "entity_id": "E6",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext/WorkloadProfile/BlockSize",
      "mapping_decision": "exact",
      "notes": "4KB block size is explicitly used in the experiments."
    },
    {
      "label": "QD128",
      "entity_id": "E7",
      "taxonomy_path": "SSD/EnvironmentalAndOperationalContext/WorkloadProfile/QueueDepth",
      "mapping_decision": "exact",
      "notes": "Queue depth of 128 is explicitly mentioned in the workload description."
    }
  ],
  "new_concepts": [],
  "paper_original_filename": "Understanding Write Behaviors of Storage Backends in Ceph.pdf"
}